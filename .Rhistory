library("ARI")
install.packages("ARI", dependencies = TRUE)
install.packages("ari", dependencies = TRUE)
lambdas <- c("10000.0", "1000.0", "100.0", "10.0", "1.0", "0.1", "0.01", "0.001", "0.0001", "1e-05", "0.0")
lambdas <- rev(lambdas)
cos_nmi <- c()
cos_ari <- c()
for(lambda in lambdas){
#file <- paste("result_wc_nmtf/lambda/cos/wc-nmtf_Z_l", lambda, ".csv", sep = "")
file <- paste("result_wc_nmtf/lambda/p_tra/wc-nmtf_Z_l", lambda, "_p_tra.csv", sep = "")
res_wc_nmtf <- read.csv(file, header = TRUE)
res_wc_nmtf <- t( normalize( t(res_wc_nmtf) ) )
label_res <- apply(res_wc_nmtf, MARGIN = 1, FUN=which.max)
t_nmi <- NMI(label_res, labelK)
t_ari <- ARI(label_res, labelK)
cos_nmi <- c(cos_nmi, t_nmi)
cos_ari <- c(cos_ari, t_ari)
}
for(lambda in lambdas){
#file <- paste("result_wc_nmtf/lambda/cos/wc-nmtf_Z_l", lambda, ".csv", sep = "")
file <- paste("result_wc_nmtf/lambda/p_tra/wc-nmtf_Z_l", lambda, "_p_tra.csv", sep = "")
res_wc_nmtf <- read.csv(file, header = TRUE)
res_wc_nmtf <- t( normalize( t(res_wc_nmtf) ) )
label_res <- apply(res_wc_nmtf, MARGIN = 1, FUN=which.max)
t_nmi <- NMI(label_res, labelK)
t_ari <- ARI(label_res, labelK)
cos_nmi <- c(cos_nmi, t_nmi)
cos_ari <- c(cos_ari, t_ari)
}
temp = c(1:10)
matrix(c, nrow = 5)
matrix(temp, nrow = 5)
t <- Sys.time()
t2 <- Sys.time()
t2 - t
temp <- t2 - t
temp
plot(temp)
?dist
?svg
setwd("/media/matthieu/Data/Matthieu/##Etude/#M1/S2/BD2/opinion-mining")
lexicon_sent <- read.csv("results/tweets_clean10.csv_lexicon_sentiment_pos_neg.csv", row.names = 1)
n_pos <- length(lexicon_sent[lexicon_sent == 1])
n_neg <- length(lexicon_sent[lexicon_sent == 0])
lexicon_sent <- read.csv("results/tweets_clean10.csv_lexicon_sentiment.csv")
n_pos <- length(lexicon_sent[lexicon_sent == 1])
n_neg <- length(lexicon_sent[lexicon_sent == 0])
lexicon_sent <- read.csv("results/tweets_clean10.csv_lexicon_sentiment.csv")
n_pos <- length(lexicon_sent[lexicon_sent == 1])
n_neg <- length(lexicon_sent[lexicon_sent == 0])
lexicon_sent <- read.csv("results/tweets_clean10.csv_lexicon_sentiment_pos_neg.csv", row.names = 1)
n_pos <- length(lexicon_sent[lexicon_sent == 1])
n_neg <- length(lexicon_sent[lexicon_sent == 0])
lexicon_sent <- read.csv("results/tweets_clean10.csv_lexicon_sentiment.csv")
lexicon_sent
lexicon_sent <- read.csv("results/tweets_clean10.csv_lexicon_sentiment.csv")
n_pos <- length(lexicon_sent[lexicon_sent == 1])
n_neg <- length(lexicon_sent[lexicon_sent == 0])
lexicon_sent <- read.csv("results/tweets_clean10.csv_lexicon_sentiment_pos_neg.csv", row.names = 1)
n_pos <- length(lexicon_sent[lexicon_sent == 1])
n_neg <- length(lexicon_sent[lexicon_sent == 0])
lexicon_sent <- read.csv("results/tweets_clean10.csv_lexicon_sentiment_pos_neg.csv", row.names = 1)
n_pos <- length(lexicon_sent[lexicon_sent == 1])
n_neg <- length(lexicon_sent[lexicon_sent == 0])
n_neu <- length(lexicon_sent[lexicon_sent == 0.5])
lexicon_sent <- read.csv("results/tweets_clean10.csv_lexicon_sentiment.csv")
n_pos <- length(lexicon_sent[lexicon_sent == 1])
n_neg <- length(lexicon_sent[lexicon_sent == 0])
n_neu <- length(lexicon_sent[lexicon_sent == 0.5])
lexicon_sent <- read.csv("results/tweets_clean10.csv_lexicon_sentiment_pos_neg.csv", row.names = 1)
n_pos <- length(lexicon_sent[lexicon_sent == 1])
n_neg <- length(lexicon_sent[lexicon_sent == 0])
n_neu <- length(lexicon_sent[lexicon_sent == 0.5])
dim(lexicon_sent)
